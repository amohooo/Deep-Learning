# ğŸ§  Handwritten Digit Classification Using SVHN and Deep Learning

## ğŸ“˜ Project Overview

This project focuses on building and evaluating **machine learning and deep learning models** to classify digits from the **Street View House Numbers (SVHN)** dataset â€” a real-world alternative to the MNIST dataset. It explores traditional machine learning using **SVM**, and advanced neural network-based approaches using **VGG-style convolutional neural networks (CNNs)**.

---

## ğŸ¯ Objectives

- Load and preprocess SVHN image data from `.mat` files
- Explore data through visual inspection and shape transformations
- Train and evaluate:
  - ğŸ§® A **Support Vector Machine (SVM)** using vectorized image features
  - ğŸ§  A **VGG-style CNN** with and without data augmentation
- Track and compare:
  - Accuracy and classification performance
  - Training time and inference time
- Visualize model performance with confusion matrices and loss/accuracy plots

---

## ğŸ§  What I Learned

Through this project, I gained practical experience in:

- ğŸ—‚ Data loading and preprocessing (reshaping, grayscale conversion, normalization)
- ğŸ“‰ Dimensionality reduction via image resizing
- ğŸ” Implementing **Support Vector Machine (SVM)** classification using raw pixel vectors
- ğŸ§ª Building, training, and validating a **deep convolutional neural network**
- âš™ï¸ Applying **data augmentation** to improve generalization
- â± Measuring and comparing **training and inference times**
- ğŸ“Š Evaluating models using confusion matrices, F1 scores, and classification reports
- ğŸ§± Designing CNN architectures using `Keras` and `TensorFlow`

---

## ğŸ› ï¸ Tools & Technologies

- **Programming Language**: Python
- **Libraries Used**:
  - `TensorFlow`, `Keras` â€“ Deep learning
  - `scikit-learn` â€“ SVM, evaluation metrics
  - `OpenCV` â€“ Grayscale conversion
  - `Seaborn`, `Matplotlib` â€“ Visualization
  - `NumPy`, `SciPy` â€“ Data manipulation
  - `cv2`, `loadmat` â€“ Image and `.mat` file handling

---

## ğŸ” Model Summary

### ğŸ”¹ Support Vector Machine (SVM)
- Vectorized RGB images into flat feature vectors
- Trained a linear SVM using `sklearn`
- Evaluated on both training and test sets
- Visualized performance via confusion matrix and classification report

### ğŸ”¹ VGG-Style CNN (Without Augmentation)
- Custom architecture using Conv2D, MaxPooling, Dropout, and Dense layers
- Used categorical cross-entropy and accuracy metrics
- Class-weight balancing to handle imbalanced classes
- Trained with early stopping

### ğŸ”¹ VGG-Style CNN (With Data Augmentation)
- Applied random flipping, rotation, zoom, contrast, and brightness transformations
- Used `tf.data.Dataset` API for efficient loading and augmentation
- Demonstrated improved generalization and performance on unseen data

---

## ğŸ§ª Evaluation & Results

All models were evaluated using:

- âœ… Accuracy on both training and test sets
- ğŸ“Š Confusion matrices (normalized)
- ğŸ“ˆ F1-score (macro and weighted)
- ğŸ“ Classification reports
- â± Training and inference times (in seconds)

Visual outputs include:
- Confusion matrix heatmaps
- Training/validation accuracy and loss curves
- Grids of classified images with labels

---

## ğŸš€ How to Run

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install numpy scipy pandas matplotlib seaborn opencv-python tensorflow scikit-learn
3. Run the SVM and VGG model scripts to reproduce training and evaluation

